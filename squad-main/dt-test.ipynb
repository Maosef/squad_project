{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import util\n",
    "\n",
    "from args import get_test_args\n",
    "from collections import OrderedDict\n",
    "from json import dumps\n",
    "from models import BiDAF,BiDAFDT\n",
    "from os.path import join\n",
    "#from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from ujson import load as json_load\n",
    "from util import collate_fn, SQuAD\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_path = 'save/train/bidaf-01/best.pth.tar'\n",
    "model_path = 'save/train/dt-04/best.pth.tar'\n",
    "\n",
    "word2idx_path = 'data/word2idx.json'\n",
    "\n",
    "# python test.py --split SPLIT --load_path PATH --name NAME\n",
    "# python test.py --split dev --load_path save/train/baseline-01/step_50048.pth.tar --name first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments: get_train_args\n",
    "\n",
    "import argparse\n",
    "from args import add_common_args, add_train_test_args\n",
    "\n",
    "parser = argparse.ArgumentParser('Test a trained model on SQuAD')\n",
    "\n",
    "add_common_args(parser)\n",
    "add_train_test_args(parser)\n",
    "\n",
    "\n",
    "parser.add_argument('--eval_steps',\n",
    "                    type=int,\n",
    "                    default=50000,\n",
    "                    help='Number of steps between successive evaluations.')\n",
    "parser.add_argument('--lr',\n",
    "                    type=float,\n",
    "                    default=0.5,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--l2_wd',\n",
    "                    type=float,\n",
    "                    default=0,\n",
    "                    help='L2 weight decay.')\n",
    "parser.add_argument('--num_epochs',\n",
    "                    type=int,\n",
    "                    default=30,\n",
    "                    help='Number of epochs for which to train. Negative means forever.')\n",
    "parser.add_argument('--drop_prob',\n",
    "                    type=float,\n",
    "                    default=0.2,\n",
    "                    help='Probability of zeroing an activation in dropout layers.')\n",
    "parser.add_argument('--metric_name',\n",
    "                    type=str,\n",
    "                    default='F1',\n",
    "                    choices=('NLL', 'EM', 'F1'),\n",
    "                    help='Name of dev metric to determine best checkpoint.')\n",
    "parser.add_argument('--max_checkpoints',\n",
    "                    type=int,\n",
    "                    default=5,\n",
    "                    help='Maximum number of checkpoints to keep on disk.')\n",
    "parser.add_argument('--max_grad_norm',\n",
    "                    type=float,\n",
    "                    default=5.0,\n",
    "                    help='Maximum gradient norm for gradient clipping.')\n",
    "parser.add_argument('--seed',\n",
    "                    type=int,\n",
    "                    default=224,\n",
    "                    help='Random seed for reproducibility.')\n",
    "parser.add_argument('--ema_decay',\n",
    "                    type=float,\n",
    "                    default=0.999,\n",
    "                    help='Decay rate for exponential moving average of parameters.')\n",
    "\n",
    "\n",
    "params = f'--load_path {model_path} --name dt --use_squad_v2 False'.split()\n",
    "args = parser.parse_args(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.01.21 00:28:29] Args: {\n",
      "    \"batch_size\": 16,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"drop_prob\": 0.2,\n",
      "    \"ema_decay\": 0.999,\n",
      "    \"eval_steps\": 50000,\n",
      "    \"hidden_size\": 100,\n",
      "    \"l2_wd\": 0,\n",
      "    \"load_path\": \"save/train/dt-04/best.pth.tar\",\n",
      "    \"lr\": 0.5,\n",
      "    \"max_ans_len\": 15,\n",
      "    \"max_checkpoints\": 5,\n",
      "    \"max_grad_norm\": 5.0,\n",
      "    \"metric_name\": \"F1\",\n",
      "    \"name\": \"dt\",\n",
      "    \"num_epochs\": 30,\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"save_dir\": \"./save/test/dt-02\",\n",
      "    \"seed\": 224,\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": false,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[11.01.21 00:28:29] Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Set up logging\n",
    "args.save_dir = util.get_save_dir(args.save_dir, args.name, training=False)\n",
    "log = util.get_logger(args.save_dir, args.name)\n",
    "device, gpu_ids = util.get_available_devices()\n",
    "\n",
    "args.batch_size = 16\n",
    "args.batch_size *= max(1, len(gpu_ids))\n",
    "log.info(f'Args: {dumps(vars(args), indent=4, sort_keys=True)}')\n",
    "\n",
    "\n",
    "# word to id dictionary\n",
    "word2idx_dict = json.load(open(word2idx_path))\n",
    "\n",
    "# Get embeddings\n",
    "log.info('Loading embeddings...')\n",
    "word_vectors = util.torch_from_json(args.word_emb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.01.21 00:28:35] Building dataset...\n",
      "CPU times: user 7.41 s, sys: 6.46 s, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get data loader\n",
    "log.info('Building dataset...')\n",
    "train_dataset = SQuAD(args.train_record_file, args.use_squad_v2)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=args.batch_size,\n",
    "                               shuffle=True,\n",
    "                               num_workers=args.num_workers,\n",
    "                               collate_fn=collate_fn)\n",
    "dev_dataset = SQuAD(args.dev_record_file, args.use_squad_v2)\n",
    "dev_loader = data.DataLoader(dev_dataset,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=args.num_workers,\n",
    "                             collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.01.21 00:28:48] Building model...\n",
      "[11.01.21 00:28:51] Loading checkpoint from save/train/dt-04/best.pth.tar...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BiDAFDT(\n",
       "    (emb): Embedding(\n",
       "      (embed): Embedding(88714, 300)\n",
       "      (proj): Linear(in_features=300, out_features=100, bias=False)\n",
       "      (hwy): HighwayEncoder(\n",
       "        (transforms): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (gates): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): RNNEncoder(\n",
       "      (rnn): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (att): BiDAFAttention()\n",
       "    (mod): RNNEncoder(\n",
       "      (rnn): LSTM(800, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (dt): RNNEncoder(\n",
       "      (rnn): LSTM(200, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (out): BiDAFOutput(\n",
       "      (att_linear_1): Linear(in_features=800, out_features=1, bias=True)\n",
       "      (mod_linear_1): Linear(in_features=200, out_features=1, bias=True)\n",
       "      (rnn): RNNEncoder(\n",
       "        (rnn): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
       "      )\n",
       "      (att_linear_2): Linear(in_features=800, out_features=1, bias=True)\n",
       "      (mod_linear_2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "import layers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BiDAFDT(nn.Module):\n",
    "    \"\"\"Baseline BiDAF model for SQuAD.\n",
    "\n",
    "    Based on the paper:\n",
    "    \"Bidirectional Attention Flow for Machine Comprehension\"\n",
    "    by Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi\n",
    "    (https://arxiv.org/abs/1611.01603).\n",
    "\n",
    "    Follows a high-level structure commonly found in SQuAD models:\n",
    "        - Embedding layer: Embed word indices to get word vectors.\n",
    "        - Encoder layer: Encode the embedded sequence.\n",
    "        - Attention layer: Apply an attention mechanism to the encoded sequence.\n",
    "        - Model encoder layer: Encode the sequence again.\n",
    "        - Output layer: Simple layer (e.g., fc + softmax) to get final outputs.\n",
    "\n",
    "    Args:\n",
    "        word_vectors (torch.Tensor): Pre-trained word vectors.\n",
    "        hidden_size (int): Number of features in the hidden state at each layer.\n",
    "        drop_prob (float): Dropout probability.\n",
    "    \"\"\"\n",
    "    def __init__(self, word_vectors, hidden_size, drop_prob=0., train_mode=False):\n",
    "        super(BiDAFDT, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        self.emb = layers.Embedding(word_vectors=word_vectors,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    drop_prob=drop_prob)\n",
    "\n",
    "        self.enc = layers.RNNEncoder(input_size=hidden_size,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=1,\n",
    "                                     drop_prob=drop_prob)\n",
    "\n",
    "        self.att = layers.BiDAFAttention(hidden_size=2 * hidden_size,\n",
    "                                         drop_prob=drop_prob)\n",
    "\n",
    "        self.mod = layers.RNNEncoder(input_size=8 * hidden_size,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=2,\n",
    "                                     drop_prob=drop_prob)\n",
    "        \n",
    "        self.dt = layers.RNNEncoder(input_size=2*hidden_size,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=2,\n",
    "                                     drop_prob=drop_prob)\n",
    "\n",
    "    \n",
    "        self.out = layers.BiDAFOutput(hidden_size=hidden_size,\n",
    "                                      drop_prob=drop_prob)\n",
    "\n",
    "\n",
    "    def forward(self, cw_idxs, qw_idxs, iters_to_do=1):\n",
    "        c_mask = torch.zeros_like(cw_idxs) != cw_idxs\n",
    "        q_mask = torch.zeros_like(qw_idxs) != qw_idxs\n",
    "        c_len, q_len = c_mask.sum(-1), q_mask.sum(-1)\n",
    "\n",
    "        c_emb = self.emb(cw_idxs)         # (batch_size, c_len, hidden_size)\n",
    "        q_emb = self.emb(qw_idxs)         # (batch_size, q_len, hidden_size)\n",
    "\n",
    "        c_enc = self.enc(c_emb, c_len)    # (batch_size, c_len, 2 * hidden_size)\n",
    "        q_enc = self.enc(q_emb, q_len)    # (batch_size, q_len, 2 * hidden_size)\n",
    "        # add DT here?\n",
    "\n",
    "        att = self.att(c_enc, q_enc,\n",
    "                       c_mask, q_mask)    # (batch_size, c_len, 8 * hidden_size)\n",
    "\n",
    "        mod = self.mod(att, c_len)        # (batch_size, c_len, 2 * hidden_size)\n",
    "        \n",
    "#         # add DT here?\n",
    "#         interim_thought = mod.to(device)\n",
    "        interim_thought = mod\n",
    "\n",
    "        # all_outputs = torch.zeros((x.size(0), iters_to_do, 2, x.size(2))).to(x.device)\n",
    "        interim_thoughts = []\n",
    "        \n",
    "        for i in range(iters_to_do):\n",
    "            # if self.recall:\n",
    "            #     interim_thought = torch.cat([interim_thought, x], 1)\n",
    "                # in: 800\n",
    "#             print(interim_thought.shape, c_len.shape)\n",
    "            interim_thought = self.dt(interim_thought, c_len)\n",
    "#             interim_thought = self.recur_block(interim_thought)\n",
    "#             out = self.head(interim_thought)\n",
    "        # all_outputs[:, i] = out\n",
    "            if not self.train_mode:\n",
    "                interim_thoughts.append(interim_thought)\n",
    "\n",
    "#         mod = interim_thought\n",
    "        out = self.out(att, mod, c_mask)  # 2 tensors, each (batch_size, c_len)\n",
    "#         # add DT here?\n",
    "        \n",
    "        if self.train_mode:\n",
    "            return out\n",
    "        else:\n",
    "            # run outputs thru head\n",
    "            all_outputs = []\n",
    "            for thought in interim_thoughts:\n",
    "                all_outputs.append(self.out(att, thought, c_mask))\n",
    "            return all_outputs\n",
    "    \n",
    "# Get model\n",
    "log.info('Building model...')\n",
    "model = BiDAFDT(word_vectors=word_vectors,\n",
    "              hidden_size=args.hidden_size,\n",
    "               train_mode=False)\n",
    "model = nn.DataParallel(model, gpu_ids)\n",
    "\n",
    "\n",
    "log.info(f'Loading checkpoint from {args.load_path}...')\n",
    "model = util.load_model(model, args.load_path, gpu_ids, return_step=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimizer and scheduler\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters(), args.lr,\n",
    "                           weight_decay=args.l2_wd)\n",
    "scheduler = sched.LambdaLR(optimizer, lambda s: 1.)  # Constant LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train\n",
    "\n",
    "# step = 0\n",
    "# args.num_epochs = 5\n",
    "\n",
    "# # Train\n",
    "# log.info('Training...')\n",
    "# #     steps_till_eval = args.eval_steps\n",
    "# epoch = step // len(train_dataset)\n",
    "# while epoch != args.num_epochs:\n",
    "#     epoch += 1\n",
    "#     log.info(f'Starting epoch {epoch}...')\n",
    "#     with torch.enable_grad(), \\\n",
    "#             tqdm(total=len(train_loader.dataset)) as progress_bar:\n",
    "#         for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in train_loader:\n",
    "#             # Setup for forward\n",
    "#             cw_idxs = cw_idxs.to(device)\n",
    "#             qw_idxs = qw_idxs.to(device)\n",
    "#             batch_size = cw_idxs.size(0)\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward\n",
    "# #             log_p1, log_p2 = model(cw_idxs, qw_idxs)\n",
    "# #             y1, y2 = y1.to(device), y2.to(device)\n",
    "# #             loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "# #             loss_val = loss.item()\n",
    "\n",
    "#             thoughts = model(cw_idxs, qw_idxs, iters_to_do=10)\n",
    "    \n",
    "#             print(len(thoughts))\n",
    "\n",
    "\n",
    "#             break\n",
    "\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 816/2848 [00:27<01:07, 30.00it/s, NLL=6.87]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 22.287655333235634),\n",
       "              ('EM', 15.441176470588236)]),\n",
       " 2: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 23.98113240355094),\n",
       "              ('EM', 16.666666666666668)]),\n",
       " 3: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 23.613485344727412),\n",
       "              ('EM', 16.29901960784314)]),\n",
       " 4: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 23.613485344727412),\n",
       "              ('EM', 16.29901960784314)]),\n",
       " 5: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 23.613485344727412),\n",
       "              ('EM', 16.29901960784314)]),\n",
       " 10: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 23.613485344727412),\n",
       "              ('EM', 16.29901960784314)]),\n",
       " 20: OrderedDict([('NLL', 6.8717976070585705),\n",
       "              ('F1', 23.613485344727412),\n",
       "              ('EM', 16.29901960784314)])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate(model, data_loader, device, eval_file, max_len, use_squad_v2, iterations):\n",
    "    \n",
    "    max_iters = max(iterations)\n",
    "    \n",
    "    nll_meter = util.AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "#     pred_dict = {}\n",
    "    predictions_by_iterations = defaultdict(dict)\n",
    "    with open(eval_file, 'r') as fh:\n",
    "        gold_dict = json_load(fh)\n",
    "        \n",
    "    i = 0\n",
    "    with torch.no_grad(), \\\n",
    "            tqdm(total=len(data_loader.dataset)) as progress_bar:\n",
    "        for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in data_loader:\n",
    "            # Setup for forward\n",
    "            cw_idxs = cw_idxs.to(device)\n",
    "            qw_idxs = qw_idxs.to(device)\n",
    "            batch_size = cw_idxs.size(0)\n",
    "\n",
    "            # Forward\n",
    "#             log_p1, log_p2 = model(cw_idxs, qw_idxs)\n",
    "            all_output = model(cw_idxs, qw_idxs, max_iters)\n",
    "            for iters in range(max_iters):\n",
    "                log_p1, log_p2 = all_output[iters]\n",
    "            \n",
    "                y1, y2 = y1.to(device), y2.to(device)\n",
    "                loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "                nll_meter.update(loss.item(), batch_size)\n",
    "\n",
    "                # Get F1 and EM scores\n",
    "                p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "                starts, ends = util.discretize(p1, p2, max_len, use_squad_v2)\n",
    "\n",
    "\n",
    "                preds, _ = util.convert_tokens(gold_dict,\n",
    "                                               ids.tolist(),\n",
    "                                               starts.tolist(),\n",
    "                                               ends.tolist(),\n",
    "                                               use_squad_v2)\n",
    "#                 pred_dict.update(preds)\n",
    "                if iters in iterations:\n",
    "                    predictions_by_iterations[iters].update(preds)\n",
    "            \n",
    "            # Log info\n",
    "            progress_bar.update(batch_size)\n",
    "            progress_bar.set_postfix(NLL=nll_meter.avg)\n",
    "\n",
    "#             print(predictions_by_iterations[1] == predictions_by_iterations[5])\n",
    "#             print(predictions_by_iterations[1] == predictions_by_iterations[10])\n",
    "\n",
    "#             break\n",
    "            i += 1\n",
    "            if i > 50:\n",
    "                break\n",
    "            \n",
    "    model.train()\n",
    "    \n",
    "    # get results for each iteration\n",
    "    \n",
    "    results_by_iteration = {}\n",
    "    for iters,pred_dict in predictions_by_iterations.items():\n",
    "        \n",
    "        results = util.eval_dicts(gold_dict, pred_dict, use_squad_v2)\n",
    "        results_list = [('NLL', nll_meter.avg),\n",
    "                        ('F1', results['F1']),\n",
    "                        ('EM', results['EM'])]\n",
    "        if use_squad_v2:\n",
    "            results_list.append(('AvNA', results['AvNA']))\n",
    "        results = OrderedDict(results_list)\n",
    "\n",
    "#         return results, pred_dict\n",
    "        results_by_iteration[iters] = results\n",
    "    return results_by_iteration, predictions_by_iterations\n",
    "\n",
    "\n",
    "# Evaluate and save checkpoint\n",
    "# log.info(f'Evaluating at step {step}...')\n",
    "# ema.assign(model)\n",
    "iterations = [1,2,3,4,5,10,20,21]\n",
    "results, pred_dict = evaluate(model, dev_loader, device,\n",
    "                              args.dev_eval_file,\n",
    "                              args.max_ans_len,\n",
    "                              args.use_squad_v2,\n",
    "                             iterations)\n",
    "\n",
    "results\n",
    "# saver.save(step, model, results[args.metric_name], device)\n",
    "# ema.resume(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.plot(y=['EM','F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5c7b9fa2e977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# def evaluate(model, data_loader, device, eval_file, max_len, use_squad_v2, iterations):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meval_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_eval_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ans_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "# def evaluate(model, data_loader, device, eval_file, max_len, use_squad_v2, iterations):\n",
    "    \n",
    "data_loader = test_loader\n",
    "eval_file = args.test_eval_file\n",
    "max_len = args.max_ans_len\n",
    "use_squad_v2 = args.use_squad_v2\n",
    "        \n",
    "max_iters = max(iterations)\n",
    "\n",
    "nll_meter = util.AverageMeter()\n",
    "\n",
    "model.eval()\n",
    "#     pred_dict = {}\n",
    "predictions_by_iterations = defaultdict(dict)\n",
    "with open(eval_file, 'r') as fh:\n",
    "    gold_dict = json_load(fh)\n",
    "\n",
    "i = 0\n",
    "with torch.no_grad(), \\\n",
    "        tqdm(total=len(data_loader.dataset)) as progress_bar:\n",
    "    for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in data_loader:\n",
    "        # Setup for forward\n",
    "        cw_idxs = cw_idxs.to(device)\n",
    "        qw_idxs = qw_idxs.to(device)\n",
    "        batch_size = cw_idxs.size(0)\n",
    "\n",
    "        # Forward\n",
    "#             log_p1, log_p2 = model(cw_idxs, qw_idxs)\n",
    "        all_output = model(cw_idxs, qw_idxs, max_iters)\n",
    "        for iters in range(max_iters):\n",
    "            log_p1, log_p2 = all_output[iters]\n",
    "\n",
    "            y1, y2 = y1.to(device), y2.to(device)\n",
    "            loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "            nll_meter.update(loss.item(), batch_size)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "# Import spacy language model\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def word_tokenize(sent):\n",
    "    doc = nlp(sent)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def preprocess(context, question, word2idx_dict, is_test=False):\n",
    "    \n",
    "    context_tokens = word_tokenize(context)\n",
    "    ques_tokens = word_tokenize(question)\n",
    "    \n",
    "#     para_limit = args.test_para_limit if is_test else args.para_limit\n",
    "#     ques_limit = args.test_ques_limit if is_test else args.ques_limit\n",
    "\n",
    "    para_limit = args.para_limit\n",
    "    ques_limit = args.ques_limit\n",
    "    ans_limit = args.ans_limit\n",
    "    \n",
    "    example = {'context_tokens': context_tokens, 'ques_tokens': ques_tokens}\n",
    "    examples = [example]\n",
    "    \n",
    "\n",
    "#     print(f\"Converting {data_type} examples to indices...\")\n",
    "    total = 0\n",
    "    total_ = 0\n",
    "    meta = {}\n",
    "    context_idxs = []\n",
    "    context_char_idxs = []\n",
    "    ques_idxs = []\n",
    "    ques_char_idxs = []\n",
    "    y1s = []\n",
    "    y2s = []\n",
    "    ids = []\n",
    "    for n, example in tqdm(enumerate(examples)):\n",
    "        total_ += 1\n",
    "\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        def _get_word(word):\n",
    "            for each in (word, word.lower(), word.capitalize(), word.upper()):\n",
    "                if each in word2idx_dict:\n",
    "                    return word2idx_dict[each]\n",
    "            return 1\n",
    "\n",
    "\n",
    "        context_idx = np.zeros([para_limit], dtype=np.int32)\n",
    "#         context_char_idx = np.zeros([para_limit, char_limit], dtype=np.int32)\n",
    "        ques_idx = np.zeros([ques_limit], dtype=np.int32)\n",
    "#         ques_char_idx = np.zeros([ques_limit, char_limit], dtype=np.int32)\n",
    "\n",
    "        for i, token in enumerate(example[\"context_tokens\"]):\n",
    "            context_idx[i] = _get_word(token)\n",
    "#         context_idxs.append(context_idx)\n",
    "\n",
    "        for i, token in enumerate(example[\"ques_tokens\"]):\n",
    "            ques_idx[i] = _get_word(token)\n",
    "#         ques_idxs.append(ques_idx)\n",
    "\n",
    "        \n",
    "        return context_idx, ques_idx\n",
    "    \n",
    "def merge_1d(arrays, dtype=torch.int64, pad_value=0):\n",
    "        lengths = [(a != pad_value).sum() for a in arrays]\n",
    "        padded = torch.zeros(len(arrays), max(lengths), dtype=dtype)\n",
    "        for i, seq in enumerate(arrays):\n",
    "            end = lengths[i]\n",
    "            padded[i, :end] = seq[:end]\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer custom questions\n",
    "\n",
    "# context = '''Southern California, often abbreviated SoCal, is a geographic and cultural region that generally comprises California's southernmost 10 counties. The region is traditionally described as \"eight counties\", based on demographics and economic ties: Imperial, Los Angeles, Orange, Riverside, San Bernardino, San Diego, Santa Barbara, and Ventura. The more extensive 10-county definition, including Kern and San Luis Obispo counties, is also used based on historical political divisions. Southern California is a major economic center for the state of California and the United States.'''\n",
    "# question = \"What is Southern California often abbreviated as?\"\n",
    "\n",
    "# context = \"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\\\"Norman\\\" comes from \\\"Norseman\\\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\"\n",
    "# question = \"In what country is Normandy located?\"\n",
    "\n",
    "question = 'Who was an accountant?'\n",
    "context = \"Mary got off the flight to visit James.\"\n",
    "\n",
    "\n",
    "\n",
    "# preprocess\n",
    "# build_features(args, train_examples, \"train\", args.train_record_file, word2idx_dict, char2idx_dict)\n",
    "\n",
    "def answer_question(context, question,always_answer=False):\n",
    "    context_idxs, ques_idxs = preprocess(context, question, word2idx_dict)\n",
    "\n",
    "    context_idxs = np.insert(context_idxs, 0, 1)\n",
    "    ques_idxs = np.insert(ques_idxs, 0, 1)\n",
    "\n",
    "    context_idxs = np.expand_dims(context_idxs, axis=0)\n",
    "    ques_idxs = np.expand_dims(ques_idxs, axis=0)\n",
    "\n",
    "\n",
    "    context_idxs = torch.from_numpy(context_idxs).long()\n",
    "    ques_idxs = torch.from_numpy(ques_idxs).long()\n",
    "\n",
    "    context_idxs = merge_1d(context_idxs)\n",
    "    ques_idxs = merge_1d(ques_idxs)\n",
    "\n",
    "    # ones = torch.ones((batch_size, 1), dtype=torch.int64)\n",
    "    # self.context_idxs = torch.cat((ones, self.context_idxs), dim=1)\n",
    "    # self.question_idxs = torch.cat((ones, self.question_idxs), dim=1)\n",
    "\n",
    "#     context_idxs, ques_idxs\n",
    "    \n",
    "    # run model\n",
    "\n",
    "#     print(context_idxs.shape, ques_idxs.shape)\n",
    "    # context_idxs, ques_idxs = data_loader.dataset[0][0], data_loader.dataset[0][2]\n",
    "    log_p1, log_p2 = model(context_idxs, ques_idxs)\n",
    "#     print(log_p1.shape, log_p2.shape)\n",
    "    p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "#     print(p1, p2, args.max_ans_len, args.use_squad_v2)\n",
    "\n",
    "    starts_all = p1.argsort()\n",
    "    ends_all = p2.argsort()\n",
    "        \n",
    "    starts, ends = util.discretize(p1, p2, args.max_ans_len, args.use_squad_v2)\n",
    "    \n",
    "    \n",
    "    context_tokens = word_tokenize(context)\n",
    "#     print(context_tokens[:10])\n",
    "\n",
    "    start_idx, end_idx = starts.item(), ends.item()\n",
    "    if (start_idx == 0 or end_idx == 0):\n",
    "#         print(\"no answer\")\n",
    "        start = list(starts_all.detach().cpu().numpy())[0][-2]\n",
    "        end = list(ends_all.detach().cpu().numpy())[0][-2]\n",
    "        \n",
    "        secondary_answer = context_tokens[start-1:end]\n",
    "        \n",
    "        if always_answer:\n",
    "            return secondary_answer\n",
    "        \n",
    "        return 'no answer'\n",
    "    \n",
    "#     return ' '.join(context_tokens[start_idx-1:end_idx])\n",
    "    return context_tokens[start_idx-1:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze gender distro of ambig results\n",
    "import json\n",
    "\n",
    "ambig_retriever_path = '../../retrieval-based-baselines/ambig_retriever_results.json'\n",
    "\n",
    "rtvr_results = json.load(open(ambig_retriever_path))\n",
    "len(rtvr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([t['title'] for t in rtvr_results[2]['ctxs']])\n",
    "\n",
    "ctxs = rtvr_results[0]['ctxs']\n",
    "len(ctxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # !pip install chicksexer\n",
    "\n",
    "# from chicksexer import predict_gender\n",
    "# # import chicksexer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_gender('Saldivar Anderson')\n",
    "# predict_gender('The Marine', return_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "from collections import defaultdict\n",
    "\n",
    "d = gender.Detector()\n",
    "\n",
    "rtvr_passage_genders = defaultdict(int)\n",
    "# rtvr_passage_genders = defaultdict(list)\n",
    "\n",
    "for res in rtvr_results:\n",
    "    res['genders'] = defaultdict(int)\n",
    "#     res['genders'] = res['question']\n",
    "    for ctx in res['ctxs']:\n",
    "#         print(ctx['title'].split()[0])\n",
    "        # filter out pages beginning with \"the\"\n",
    "        first_word = ctx['title'].split()[0]\n",
    "        if first_word.lower() in ['the','my','to']: guessed_gender='unknown'\n",
    "        else: guessed_gender = d.get_gender(first_word)\n",
    "        rtvr_passage_genders[guessed_gender] += 1\n",
    "#         rtvr_passage_genders[guessed_gender].append(ctx['title'])\n",
    "        res['genders'][guessed_gender] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtvr_passage_genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rtvr_passage_genders['andy']\n",
    "\n",
    "def gender_score(genders):\n",
    "    return -genders['male'] -genders['mostly_male'] + genders['mostly_female'] + genders['female']\n",
    "\n",
    "for res in rtvr_results:\n",
    "#     res['occupation'] = ' '.join(res['question'].split()[3:])[:-1]\n",
    "    res['occupation'] = ' '.join(res['question'].split()[3:])[:-1]\n",
    "    res['gender_score'] = gender_score(res['genders'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort by #males\n",
    "\n",
    "rtvr_results = sorted(rtvr_results, key=lambda x: x['gender_score'])\n",
    "# rtvr_results = sorted(rtvr_results, key=lambda x: x['genders']['male'])\n",
    "\n",
    "\n",
    "for res in rtvr_results:\n",
    "\n",
    "    print(res['occupation'], res['gender_score'])\n",
    "#     print(res['question'], dict(res['genders']))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top and bottom 5, plot\n",
    "\n",
    "sliced = rtvr_results[:8] + rtvr_results[-8:]\n",
    "labels = [res['occupation'] for res in sliced]\n",
    "counts = [res['gender_score'] for res in sliced]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "x = labels\n",
    "energy = counts\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "plt.bar(x_pos, energy)\n",
    "plt.xlabel(\"Occupation\")\n",
    "plt.ylabel(\"Gender Difference\")\n",
    "plt.title(\"Gender Difference by Occupation (DPR Results)\")\n",
    "\n",
    "plt.xticks(x_pos, x)\n",
    "# rotate axis labels\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models import DeepLSTM\n",
    "# from models import TestModel\n",
    "\n",
    "model = DeepLSTM(word_vectors=word_vectors,\n",
    "                  hidden_size=args.hidden_size,\n",
    "                  )\n",
    "model = nn.DataParallel(model, gpu_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluate\n",
    "log.info(f'Evaluating on {args.split} split...')\n",
    "nll_meter = util.AverageMeter()\n",
    "pred_dict = {}  # Predictions for TensorBoard\n",
    "sub_dict = {}   # Predictions for submission\n",
    "eval_file = vars(args)[f'{args.split}_eval_file']\n",
    "with open(eval_file, 'r') as fh:\n",
    "    gold_dict = json_load(fh)\n",
    "with torch.no_grad(), \\\n",
    "        tqdm(total=len(dataset)) as progress_bar:\n",
    "    i = 0\n",
    "    for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in data_loader:\n",
    "        # Setup for forward\n",
    "        cw_idxs = cw_idxs.to(device)\n",
    "        qw_idxs = qw_idxs.to(device)\n",
    "        batch_size = cw_idxs.size(0)\n",
    "\n",
    "        # Forward\n",
    "        log_p1, log_p2 = model(cw_idxs, qw_idxs)\n",
    "        y1, y2 = y1.to(device), y2.to(device)\n",
    "        loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "        nll_meter.update(loss.item(), batch_size)\n",
    "\n",
    "        # Get F1 and EM scores\n",
    "        p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "        starts, ends = util.discretize(p1, p2, args.max_ans_len, args.use_squad_v2)\n",
    "\n",
    "        # Log info\n",
    "        progress_bar.update(batch_size)\n",
    "        if args.split != 'test':\n",
    "            # No labels for the test set, so NLL would be invalid\n",
    "            progress_bar.set_postfix(NLL=nll_meter.avg)\n",
    "\n",
    "#         idx2pred, uuid2pred = util.convert_tokens(gold_dict,\n",
    "#                                                   ids.tolist(),\n",
    "#                                                   starts.tolist(),\n",
    "#                                                   ends.tolist(),\n",
    "#                                                   args.use_squad_v2)\n",
    "#         pred_dict.update(idx2pred)\n",
    "#         sub_dict.update(uuid2pred)\n",
    "        \n",
    "        i+=1\n",
    "        if i>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids) in enumerate(data_loader):\n",
    "\n",
    "    print(cw_idxs.shape)\n",
    "    print(cw_idxs)\n",
    "    \n",
    "    if i>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results (except for test set, since it does not come with labels)\n",
    "    if args.split != 'test':\n",
    "        results = util.eval_dicts(gold_dict, pred_dict, args.use_squad_v2)\n",
    "        results_list = [('NLL', nll_meter.avg),\n",
    "                        ('F1', results['F1']),\n",
    "                        ('EM', results['EM'])]\n",
    "        if args.use_squad_v2:\n",
    "            results_list.append(('AvNA', results['AvNA']))\n",
    "        results = OrderedDict(results_list)\n",
    "\n",
    "        # Log to console\n",
    "        results_str = ', '.join(f'{k}: {v:05.2f}' for k, v in results.items())\n",
    "        log.info(f'{args.split.title()} {results_str}')\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        tbx = SummaryWriter(args.save_dir)\n",
    "        util.visualize(tbx,\n",
    "                       pred_dict=pred_dict,\n",
    "                       eval_path=eval_file,\n",
    "                       step=0,\n",
    "                       split=args.split,\n",
    "                       num_visuals=args.num_visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_dict[:10]\n",
    "# sub_dict\n",
    "cw_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:squad]",
   "language": "python",
   "name": "conda-env-squad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
