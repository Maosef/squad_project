{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import util\n",
    "\n",
    "from args import get_test_args\n",
    "from collections import OrderedDict\n",
    "from json import dumps\n",
    "from models import BiDAF\n",
    "from os.path import join\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from ujson import load as json_load\n",
    "from util import collate_fn, SQuAD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = 'save/train/baseline-01/step_50048.pth.tar'\n",
    "word2idx_path = 'data/word2idx.json'\n",
    "\n",
    "# python test.py --split SPLIT --load_path PATH --name NAME\n",
    "# python test.py --split dev --load_path save/train/baseline-01/step_50048.pth.tar --name first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04.02.21 00:27:43] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/best.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-01\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[04.02.21 00:27:43] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/best.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-01\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[04.02.21 00:27:43] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/best.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-01\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# arguments\n",
    "\n",
    "import argparse\n",
    "from args import add_common_args, add_train_test_args\n",
    "\n",
    "parser = argparse.ArgumentParser('Test a trained model on SQuAD')\n",
    "\n",
    "add_common_args(parser)\n",
    "add_train_test_args(parser)\n",
    "\n",
    "parser.add_argument('--split',\n",
    "                    type=str,\n",
    "                    default='dev',\n",
    "                    choices=('train', 'dev', 'test'),\n",
    "                    help='Split to use for testing.')\n",
    "parser.add_argument('--sub_file',\n",
    "                    type=str,\n",
    "                    default='submission.csv',\n",
    "                    help='Name for submission file.')\n",
    "parser.add_argument('--para_limit',\n",
    "                    type=int,\n",
    "                    default=400,\n",
    "                    help='Max number of words in a paragraph')\n",
    "parser.add_argument('--ques_limit',\n",
    "                    type=int,\n",
    "                    default=50,\n",
    "                    help='Max number of words to keep from a question')\n",
    "parser.add_argument('--ans_limit',\n",
    "                    type=int,\n",
    "                    default=30,\n",
    "                    help='Max number of words in a training example answer')\n",
    "# Require load_path for test.py\n",
    "params = '--load_path save/train/baseline-01/best.pth.tar --name eval'.split()\n",
    "args = parser.parse_args(params)\n",
    "\n",
    "# Set up logging\n",
    "args.save_dir = util.get_save_dir(args.save_dir, args.name, training=False)\n",
    "log = util.get_logger(args.save_dir, args.name)\n",
    "log.info(f'Args: {dumps(vars(args), indent=4, sort_keys=True)}')\n",
    "device, gpu_ids = util.get_available_devices()\n",
    "args.batch_size *= max(1, len(gpu_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# word to id dictionary\n",
    "word2idx_dict = json.load(open(word2idx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04.01.21 15:38:41] Building dataset...\n"
     ]
    }
   ],
   "source": [
    "# Get data loader\n",
    "log.info('Building dataset...')\n",
    "record_file = vars(args)[f'{args.split}_record_file']\n",
    "dataset = SQuAD(record_file, args.use_squad_v2)\n",
    "data_loader = data.DataLoader(dataset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=args.num_workers,\n",
    "                              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04.01.21 15:38:44] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-02/test/eval-01\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[04.01.21 15:38:44] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-02/test/eval-01\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[04.01.21 15:38:44] Loading embeddings...\n",
      "[04.01.21 15:38:44] Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set up logging\n",
    "args.save_dir = util.get_save_dir(args.save_dir, args.name, training=False)\n",
    "log = util.get_logger(args.save_dir, args.name)\n",
    "log.info(f'Args: {dumps(vars(args), indent=4, sort_keys=True)}')\n",
    "device, gpu_ids = util.get_available_devices()\n",
    "args.batch_size *= max(1, len(gpu_ids))\n",
    "\n",
    "# Get embeddings\n",
    "log.info('Loading embeddings...')\n",
    "word_vectors = util.torch_from_json(args.word_emb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04.02.21 00:27:48] Building model...\n",
      "[04.02.21 00:27:48] Building model...\n",
      "[04.02.21 00:27:48] Building model...\n",
      "[04.02.21 00:27:48] Loading checkpoint from save/train/baseline-01/best.pth.tar...\n",
      "[04.02.21 00:27:48] Loading checkpoint from save/train/baseline-01/best.pth.tar...\n",
      "[04.02.21 00:27:48] Loading checkpoint from save/train/baseline-01/best.pth.tar...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BiDAF(\n",
       "    (emb): Embedding(\n",
       "      (embed): Embedding(88714, 300)\n",
       "      (proj): Linear(in_features=300, out_features=100, bias=False)\n",
       "      (hwy): HighwayEncoder(\n",
       "        (transforms): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (gates): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): RNNEncoder(\n",
       "      (rnn): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (att): BiDAFAttention()\n",
       "    (mod): RNNEncoder(\n",
       "      (rnn): LSTM(800, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (out): BiDAFOutput(\n",
       "      (att_linear_1): Linear(in_features=800, out_features=1, bias=True)\n",
       "      (mod_linear_1): Linear(in_features=200, out_features=1, bias=True)\n",
       "      (rnn): RNNEncoder(\n",
       "        (rnn): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
       "      )\n",
       "      (att_linear_2): Linear(in_features=800, out_features=1, bias=True)\n",
       "      (mod_linear_2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model\n",
    "log.info('Building model...')\n",
    "model = BiDAF(word_vectors=word_vectors,\n",
    "              hidden_size=args.hidden_size)\n",
    "model = nn.DataParallel(model, gpu_ids)\n",
    "log.info(f'Loading checkpoint from {args.load_path}...')\n",
    "model = util.load_model(model, args.load_path, gpu_ids, return_step=False)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "# Import spacy language model\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def word_tokenize(sent):\n",
    "    doc = nlp(sent)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def preprocess(context, question, word2idx_dict, is_test=False):\n",
    "    \n",
    "    context_tokens = word_tokenize(context)\n",
    "    ques_tokens = word_tokenize(question)\n",
    "    \n",
    "#     para_limit = args.test_para_limit if is_test else args.para_limit\n",
    "#     ques_limit = args.test_ques_limit if is_test else args.ques_limit\n",
    "\n",
    "    para_limit = args.para_limit\n",
    "    ques_limit = args.ques_limit\n",
    "    ans_limit = args.ans_limit\n",
    "    \n",
    "    example = {'context_tokens': context_tokens, 'ques_tokens': ques_tokens}\n",
    "    examples = [example]\n",
    "    \n",
    "\n",
    "#     print(f\"Converting {data_type} examples to indices...\")\n",
    "    total = 0\n",
    "    total_ = 0\n",
    "    meta = {}\n",
    "    context_idxs = []\n",
    "    context_char_idxs = []\n",
    "    ques_idxs = []\n",
    "    ques_char_idxs = []\n",
    "    y1s = []\n",
    "    y2s = []\n",
    "    ids = []\n",
    "    for n, example in tqdm(enumerate(examples)):\n",
    "        total_ += 1\n",
    "\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        def _get_word(word):\n",
    "            for each in (word, word.lower(), word.capitalize(), word.upper()):\n",
    "                if each in word2idx_dict:\n",
    "                    return word2idx_dict[each]\n",
    "            return 1\n",
    "\n",
    "\n",
    "        context_idx = np.zeros([para_limit], dtype=np.int32)\n",
    "#         context_char_idx = np.zeros([para_limit, char_limit], dtype=np.int32)\n",
    "        ques_idx = np.zeros([ques_limit], dtype=np.int32)\n",
    "#         ques_char_idx = np.zeros([ques_limit, char_limit], dtype=np.int32)\n",
    "\n",
    "        for i, token in enumerate(example[\"context_tokens\"]):\n",
    "            context_idx[i] = _get_word(token)\n",
    "#         context_idxs.append(context_idx)\n",
    "\n",
    "        for i, token in enumerate(example[\"ques_tokens\"]):\n",
    "            ques_idx[i] = _get_word(token)\n",
    "#         ques_idxs.append(ques_idx)\n",
    "\n",
    "        \n",
    "        return context_idx, ques_idx\n",
    "    \n",
    "def merge_1d(arrays, dtype=torch.int64, pad_value=0):\n",
    "        lengths = [(a != pad_value).sum() for a in arrays]\n",
    "        padded = torch.zeros(len(arrays), max(lengths), dtype=dtype)\n",
    "        for i, seq in enumerate(arrays):\n",
    "            end = lengths[i]\n",
    "            padded[i, :end] = seq[:end]\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# answer custom questions\n",
    "\n",
    "# context = '''Southern California, often abbreviated SoCal, is a geographic and cultural region that generally comprises California's southernmost 10 counties. The region is traditionally described as \"eight counties\", based on demographics and economic ties: Imperial, Los Angeles, Orange, Riverside, San Bernardino, San Diego, Santa Barbara, and Ventura. The more extensive 10-county definition, including Kern and San Luis Obispo counties, is also used based on historical political divisions. Southern California is a major economic center for the state of California and the United States.'''\n",
    "# question = \"What is Southern California often abbreviated as?\"\n",
    "\n",
    "context = \"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\\\"Norman\\\" comes from \\\"Norseman\\\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\"\n",
    "question = \"In what country is Normandy located?\"\n",
    "\n",
    "# preprocess\n",
    "# build_features(args, train_examples, \"train\", args.train_record_file, word2idx_dict, char2idx_dict)\n",
    "\n",
    "def answer_question(context, question):\n",
    "    context_idxs, ques_idxs = preprocess(context, question, word2idx_dict)\n",
    "\n",
    "    context_idxs = np.insert(context_idxs, 0, 1)\n",
    "    ques_idxs = np.insert(ques_idxs, 0, 1)\n",
    "\n",
    "    context_idxs = np.expand_dims(context_idxs, axis=0)\n",
    "    ques_idxs = np.expand_dims(ques_idxs, axis=0)\n",
    "\n",
    "\n",
    "    context_idxs = torch.from_numpy(context_idxs).long()\n",
    "    ques_idxs = torch.from_numpy(ques_idxs).long()\n",
    "\n",
    "    context_idxs = merge_1d(context_idxs)\n",
    "    ques_idxs = merge_1d(ques_idxs)\n",
    "\n",
    "    # ones = torch.ones((batch_size, 1), dtype=torch.int64)\n",
    "    # self.context_idxs = torch.cat((ones, self.context_idxs), dim=1)\n",
    "    # self.question_idxs = torch.cat((ones, self.question_idxs), dim=1)\n",
    "\n",
    "#     context_idxs, ques_idxs\n",
    "    \n",
    "    # run model\n",
    "\n",
    "    # print(context_idxs.shape, ques_idxs.shape)\n",
    "\n",
    "    # context_idxs, ques_idxs = data_loader.dataset[0][0], data_loader.dataset[0][2]\n",
    "    log_p1, log_p2 = model(context_idxs, ques_idxs)\n",
    "    p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "    starts, ends = util.discretize(p1, p2, args.max_ans_len, args.use_squad_v2)\n",
    "    \n",
    "    context_tokens = word_tokenize(context)\n",
    "#     print(context_tokens[:10])\n",
    "\n",
    "    start_idx, end_idx = starts.item(), ends.item()\n",
    "    if (start_idx == 0 or end_idx == 0):\n",
    "        print(\"no answer\")\n",
    "    print(context_tokens[start_idx-1:end_idx])\n",
    "    \n",
    "answer_question(context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity theory\n",
      "Computational complexity theory Computational complexity theory focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm. A problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying their computational complexity, i.e., the amount of resources needed to solve them, such as time and storage. Other\n",
      "Computational complexity theory\n",
      "widely believed that if a problem turned out to be NP-complete, then there was little chance of being able to work with the problem in a practical situation. However, it became increasingly clear that this is not always the case, and some authors claimed that general asymptotic results are often unimportant for typical problems arising in practice. Computational complexity theory Computational complexity theory focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical\n",
      "Theoretical computer science\n",
      "methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Storing and retrieving can be carried out on data stored in both main memory and in secondary memory. Computational complexity theory is a branch of the theory of computation that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of\n",
      "Parameterized complexity\n",
      "Parameterized complexity In computer science, parameterized complexity is a branch of computational complexity theory that focuses on classifying computational problems according to their inherent difficulty with respect to \"multiple\" parameters of the input or output. The complexity of a problem is then measured as a function of those parameters. This allows the classification of NP-hard problems on a finer scale than in the classical setting, where the complexity of a problem is only measured by the number of bits in the input. The first systematic work on parameterized complexity was done by . Under the assumption that P â‰  NP,\n",
      "Parameterized complexity\n",
      "Therefore we can select a subset formula_38 with formula_39 nondeterministic choices. XP is the class of parameterized problems that can be solved in time formula_40 for some computable function . The A hierarchy is a collection of computational complexity classes similar to the W hierarchy. However, while the W hierarchy is a hierarchy contained in NP, the A hierarchy more closely mimics the polynomial-time hierarchy from classical complexity. It is known that A[1] = W[1] holds. Parameterized complexity In computer science, parameterized complexity is a branch of computational complexity theory that focuses on classifying computational problems according to their inherent\n",
      "European Association for Theoretical Computer Science\n",
      "European Association for Theoretical Computer Science The European Association for Theoretical Computer Science (EATCS) is an international organization with a European focus, founded in 1972. Its aim is to facilitate the exchange of ideas and results among theoretical computer scientists as well as to stimulate cooperation between the theoretical and the practical community in computer science. The major activities of the EATCS are: Each year, the EATCS Award is awarded in recognition of a distinguished career in theoretical computer science. The first award was assigned to Richard Karp in 2000; the complete list of the winners is given below: Starting\n",
      "Computational problem\n",
      "Computational problem In theoretical computer science, a computational problem is a mathematical object representing a collection of questions that computers might be able to solve. For example, the problem of factoring is a computational problem. Computational problems are one of the main objects of study in theoretical computer science. The field of algorithms studies methods of solving computational problems efficiently. The complementary field of computational complexity attempts to explain why certain computational problems are intractable for computers. A computational problem can be viewed as an infinite collection of \"instances\" together with a \"solution\" for every instance. For example, in the\n",
      "Computational problem\n",
      "testing, and interactive proof systems. Computational problem In theoretical computer science, a computational problem is a mathematical object representing a collection of questions that computers might be able to solve. For example, the problem of factoring is a computational problem. Computational problems are one of the main objects of study in theoretical computer science. The field of algorithms studies methods of solving computational problems efficiently. The complementary field of computational complexity attempts to explain why certain computational problems are intractable for computers. A computational problem can be viewed as an infinite collection of \"instances\" together with a \"solution\" for every\n",
      "British Colloquium for Theoretical Computer Science\n",
      "British Colloquium for Theoretical Computer Science The British Colloquium for Theoretical Computer Science (BCTCS) is an organisation that hosts an annual event for UK-based researchers in theoretical computer science. A central aspect of BCTCS is the training of PhD students. The purpose of BCTCS is: The scope of BCTCS includes all aspects of theoretical computer science, including algorithms, complexity, semantics, formal methods, concurrency, types, languages and logics. An emphasis on breadth, together with the inherently mathematical nature of theoretical computer science, means that BCTCS always actively solicits both computer scientists and mathematicians as participants, and offers an environment within which\n",
      "British Colloquium for Theoretical Computer Science\n",
      "and Treasurer. The current President is Faron Moller. British Colloquium for Theoretical Computer Science The British Colloquium for Theoretical Computer Science (BCTCS) is an organisation that hosts an annual event for UK-based researchers in theoretical computer science. A central aspect of BCTCS is the training of PhD students. The purpose of BCTCS is: The scope of BCTCS includes all aspects of theoretical computer science, including algorithms, complexity, semantics, formal methods, concurrency, types, languages and logics. An emphasis on breadth, together with the inherently mathematical nature of theoretical computer science, means that BCTCS always actively solicits both computer scientists and mathematicians\n"
     ]
    }
   ],
   "source": [
    "# retriever API\n",
    "\n",
    "import requests\n",
    "\n",
    "# query = \"In what country is Normandy located?\"\n",
    "query = \"What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?\"\n",
    "\n",
    "limit = 10\n",
    "r = requests.get(f\"http://127.0.0.1:5000/search_passages?query={query}&n_docs={limit}\")\n",
    "# r = requests.get(f\"http://127.0.0.1:5000/get_document_by_id/{doc_id}\")\n",
    "assert r.status_code == requests.codes.ok\n",
    "\n",
    "search_results = r.json()\n",
    "# print('search_results', search_results)\n",
    "\n",
    "for res in search_results:\n",
    "    print(res['page'])\n",
    "    print(res['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/dev_eval.json') as fh:\n",
    "#     gold_dict = json.load(fh)\n",
    "# len(gold_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "    log.info(f'Evaluating on {args.split} split...')\n",
    "    nll_meter = util.AverageMeter()\n",
    "    pred_dict = {}  # Predictions for TensorBoard\n",
    "    sub_dict = {}   # Predictions for submission\n",
    "    eval_file = vars(args)[f'{args.split}_eval_file']\n",
    "    with open(eval_file, 'r') as fh:\n",
    "        gold_dict = json_load(fh)\n",
    "    with torch.no_grad(), \\\n",
    "            tqdm(total=len(dataset)) as progress_bar:\n",
    "        for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in data_loader:\n",
    "            # Setup for forward\n",
    "            cw_idxs = cw_idxs.to(device)\n",
    "            qw_idxs = qw_idxs.to(device)\n",
    "            batch_size = cw_idxs.size(0)\n",
    "\n",
    "            # Forward\n",
    "            log_p1, log_p2 = model(cw_idxs, qw_idxs)\n",
    "            y1, y2 = y1.to(device), y2.to(device)\n",
    "            loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "            nll_meter.update(loss.item(), batch_size)\n",
    "\n",
    "            # Get F1 and EM scores\n",
    "            p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "            starts, ends = util.discretize(p1, p2, args.max_ans_len, args.use_squad_v2)\n",
    "\n",
    "            # Log info\n",
    "            progress_bar.update(batch_size)\n",
    "            if args.split != 'test':\n",
    "                # No labels for the test set, so NLL would be invalid\n",
    "                progress_bar.set_postfix(NLL=nll_meter.avg)\n",
    "\n",
    "            idx2pred, uuid2pred = util.convert_tokens(gold_dict,\n",
    "                                                      ids.tolist(),\n",
    "                                                      starts.tolist(),\n",
    "                                                      ends.tolist(),\n",
    "                                                      args.use_squad_v2)\n",
    "            pred_dict.update(idx2pred)\n",
    "            sub_dict.update(uuid2pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids) in enumerate(data_loader):\n",
    "\n",
    "    print(cw_idxs.shape)\n",
    "    print(cw_idxs)\n",
    "    \n",
    "    if i>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results (except for test set, since it does not come with labels)\n",
    "    if args.split != 'test':\n",
    "        results = util.eval_dicts(gold_dict, pred_dict, args.use_squad_v2)\n",
    "        results_list = [('NLL', nll_meter.avg),\n",
    "                        ('F1', results['F1']),\n",
    "                        ('EM', results['EM'])]\n",
    "        if args.use_squad_v2:\n",
    "            results_list.append(('AvNA', results['AvNA']))\n",
    "        results = OrderedDict(results_list)\n",
    "\n",
    "        # Log to console\n",
    "        results_str = ', '.join(f'{k}: {v:05.2f}' for k, v in results.items())\n",
    "        log.info(f'{args.split.title()} {results_str}')\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        tbx = SummaryWriter(args.save_dir)\n",
    "        util.visualize(tbx,\n",
    "                       pred_dict=pred_dict,\n",
    "                       eval_path=eval_file,\n",
    "                       step=0,\n",
    "                       split=args.split,\n",
    "                       num_visuals=args.num_visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_dict[:10]\n",
    "# sub_dict\n",
    "cw_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:squad]",
   "language": "python",
   "name": "conda-env-squad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
