{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import util\n",
    "\n",
    "from args import get_test_args\n",
    "from collections import OrderedDict\n",
    "from json import dumps\n",
    "from models import BiDAF\n",
    "from os.path import join\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from ujson import load as json_load\n",
    "from util import collate_fn, SQuAD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = 'save/train/baseline-01/step_50048.pth.tar'\n",
    "word2idx_path = 'data/word2idx.json'\n",
    "\n",
    "# python test.py --split SPLIT --load_path PATH --name NAME\n",
    "# python test.py --split dev --load_path save/train/baseline-01/step_50048.pth.tar --name first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03.19.21 00:35:52] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-05\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[03.19.21 00:35:52] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-05\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[03.19.21 00:35:52] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-05\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[03.19.21 00:35:52] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-05\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[03.19.21 00:35:52] Args: {\n",
      "    \"ans_limit\": 30,\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_1250813.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"para_limit\": 400,\n",
      "    \"ques_limit\": 50,\n",
      "    \"save_dir\": \"./save/test/eval-05\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# arguments\n",
    "\n",
    "import argparse\n",
    "from args import add_common_args, add_train_test_args\n",
    "\n",
    "parser = argparse.ArgumentParser('Test a trained model on SQuAD')\n",
    "\n",
    "add_common_args(parser)\n",
    "add_train_test_args(parser)\n",
    "\n",
    "parser.add_argument('--split',\n",
    "                    type=str,\n",
    "                    default='dev',\n",
    "                    choices=('train', 'dev', 'test'),\n",
    "                    help='Split to use for testing.')\n",
    "parser.add_argument('--sub_file',\n",
    "                    type=str,\n",
    "                    default='submission.csv',\n",
    "                    help='Name for submission file.')\n",
    "parser.add_argument('--para_limit',\n",
    "                    type=int,\n",
    "                    default=400,\n",
    "                    help='Max number of words in a paragraph')\n",
    "parser.add_argument('--ques_limit',\n",
    "                    type=int,\n",
    "                    default=50,\n",
    "                    help='Max number of words to keep from a question')\n",
    "parser.add_argument('--ans_limit',\n",
    "                    type=int,\n",
    "                    default=30,\n",
    "                    help='Max number of words in a training example answer')\n",
    "# Require load_path for test.py\n",
    "params = '--load_path save/train/baseline-01/step_1250813.pth.tar --name eval'.split()\n",
    "args = parser.parse_args(params)\n",
    "\n",
    "# Set up logging\n",
    "args.save_dir = util.get_save_dir(args.save_dir, args.name, training=False)\n",
    "log = util.get_logger(args.save_dir, args.name)\n",
    "log.info(f'Args: {dumps(vars(args), indent=4, sort_keys=True)}')\n",
    "device, gpu_ids = util.get_available_devices()\n",
    "args.batch_size *= max(1, len(gpu_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "word2idx_dict = json.load(open(word2idx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data loader\n",
    "log.info('Building dataset...')\n",
    "record_file = vars(args)[f'{args.split}_record_file']\n",
    "dataset = SQuAD(record_file, args.use_squad_v2)\n",
    "data_loader = data.DataLoader(dataset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=args.num_workers,\n",
    "                              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03.18.21 22:41:12] Args: {\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_50048.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"save_dir\": \"./save/test/eval-02\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[03.18.21 22:41:12] Args: {\n",
      "    \"batch_size\": 64,\n",
      "    \"char_emb_file\": \"./data/char_emb.json\",\n",
      "    \"dev_eval_file\": \"./data/dev_eval.json\",\n",
      "    \"dev_record_file\": \"./data/dev.npz\",\n",
      "    \"hidden_size\": 100,\n",
      "    \"load_path\": \"save/train/baseline-01/step_50048.pth.tar\",\n",
      "    \"max_ans_len\": 15,\n",
      "    \"name\": \"eval\",\n",
      "    \"num_visuals\": 10,\n",
      "    \"num_workers\": 4,\n",
      "    \"save_dir\": \"./save/test/eval-02\",\n",
      "    \"split\": \"dev\",\n",
      "    \"sub_file\": \"submission.csv\",\n",
      "    \"test_eval_file\": \"./data/test_eval.json\",\n",
      "    \"test_record_file\": \"./data/test.npz\",\n",
      "    \"train_eval_file\": \"./data/train_eval.json\",\n",
      "    \"train_record_file\": \"./data/train.npz\",\n",
      "    \"use_squad_v2\": true,\n",
      "    \"word_emb_file\": \"./data/word_emb.json\"\n",
      "}\n",
      "[03.18.21 22:41:12] Loading embeddings...\n",
      "[03.18.21 22:41:12] Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set up logging\n",
    "args.save_dir = util.get_save_dir(args.save_dir, args.name, training=False)\n",
    "log = util.get_logger(args.save_dir, args.name)\n",
    "log.info(f'Args: {dumps(vars(args), indent=4, sort_keys=True)}')\n",
    "device, gpu_ids = util.get_available_devices()\n",
    "args.batch_size *= max(1, len(gpu_ids))\n",
    "\n",
    "# Get embeddings\n",
    "log.info('Loading embeddings...')\n",
    "word_vectors = util.torch_from_json(args.word_emb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03.18.21 22:49:32] Building model...\n",
      "[03.18.21 22:49:32] Building model...\n",
      "[03.18.21 22:49:32] Loading checkpoint from save/train/baseline-01/step_1250813.pth.tar...\n",
      "[03.18.21 22:49:32] Loading checkpoint from save/train/baseline-01/step_1250813.pth.tar...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BiDAF(\n",
       "    (emb): Embedding(\n",
       "      (embed): Embedding(88714, 300)\n",
       "      (proj): Linear(in_features=300, out_features=100, bias=False)\n",
       "      (hwy): HighwayEncoder(\n",
       "        (transforms): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (gates): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): RNNEncoder(\n",
       "      (rnn): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (att): BiDAFAttention()\n",
       "    (mod): RNNEncoder(\n",
       "      (rnn): LSTM(800, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (out): BiDAFOutput(\n",
       "      (att_linear_1): Linear(in_features=800, out_features=1, bias=True)\n",
       "      (mod_linear_1): Linear(in_features=200, out_features=1, bias=True)\n",
       "      (rnn): RNNEncoder(\n",
       "        (rnn): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
       "      )\n",
       "      (att_linear_2): Linear(in_features=800, out_features=1, bias=True)\n",
       "      (mod_linear_2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model\n",
    "log.info('Building model...')\n",
    "model = BiDAF(word_vectors=word_vectors,\n",
    "              hidden_size=args.hidden_size)\n",
    "model = nn.DataParallel(model, gpu_ids)\n",
    "log.info(f'Loading checkpoint from {args.load_path}...')\n",
    "model = util.load_model(model, args.load_path, gpu_ids, return_step=False)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy language model\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def word_tokenize(sent):\n",
    "    doc = nlp(sent)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def preprocess(context, question, word2idx_dict, is_test=False):\n",
    "    \n",
    "    context_tokens = word_tokenize(context)\n",
    "    ques_tokens = word_tokenize(question)\n",
    "    \n",
    "#     para_limit = args.test_para_limit if is_test else args.para_limit\n",
    "#     ques_limit = args.test_ques_limit if is_test else args.ques_limit\n",
    "\n",
    "    para_limit = args.para_limit\n",
    "    ques_limit = args.ques_limit\n",
    "    ans_limit = args.ans_limit\n",
    "    \n",
    "    example = {'context_tokens': context_tokens, 'ques_tokens': ques_tokens}\n",
    "    examples = [example]\n",
    "    \n",
    "\n",
    "#     print(f\"Converting {data_type} examples to indices...\")\n",
    "    total = 0\n",
    "    total_ = 0\n",
    "    meta = {}\n",
    "    context_idxs = []\n",
    "    context_char_idxs = []\n",
    "    ques_idxs = []\n",
    "    ques_char_idxs = []\n",
    "    y1s = []\n",
    "    y2s = []\n",
    "    ids = []\n",
    "    for n, example in tqdm(enumerate(examples)):\n",
    "        total_ += 1\n",
    "\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        def _get_word(word):\n",
    "            for each in (word, word.lower(), word.capitalize(), word.upper()):\n",
    "                if each in word2idx_dict:\n",
    "                    return word2idx_dict[each]\n",
    "            return 1\n",
    "\n",
    "\n",
    "        context_idx = np.zeros([para_limit], dtype=np.int32)\n",
    "#         context_char_idx = np.zeros([para_limit, char_limit], dtype=np.int32)\n",
    "        ques_idx = np.zeros([ques_limit], dtype=np.int32)\n",
    "#         ques_char_idx = np.zeros([ques_limit, char_limit], dtype=np.int32)\n",
    "\n",
    "        for i, token in enumerate(example[\"context_tokens\"]):\n",
    "            context_idx[i] = _get_word(token)\n",
    "#         context_idxs.append(context_idx)\n",
    "\n",
    "        for i, token in enumerate(example[\"ques_tokens\"]):\n",
    "            ques_idx[i] = _get_word(token)\n",
    "#         ques_idxs.append(ques_idx)\n",
    "\n",
    "        \n",
    "        return context_idx, ques_idx\n",
    "    \n",
    "def merge_1d(arrays, dtype=torch.int64, pad_value=0):\n",
    "        lengths = [(a != pad_value).sum() for a in arrays]\n",
    "        padded = torch.zeros(len(arrays), max(lengths), dtype=dtype)\n",
    "        for i, seq in enumerate(arrays):\n",
    "            end = lengths[i]\n",
    "            padded[i, :end] = seq[:end]\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,  2696,   807,     2,   464, 25972,     1,     2,    12,     8,\n",
       "          12769,     5,  3114,  1556,    17,  1742,  6071,   807,    22, 42451,\n",
       "            168,  8676,     3,    24,  1556,    12, 10926,  1918,    30,    10,\n",
       "           2241,  8676,    10,     2,   439,    19, 19591,     5,  1403,  6840,\n",
       "             11,  9495,     2,  1625,  1879,     2,  3297,     2, 10889,     2,\n",
       "            782, 22439,     2,   782,  3456,     2,  2384,  5120,     2,     5,\n",
       "          16012,     3,    24,    51,  3366,     1,  3135,     2,   278,     1,\n",
       "              5,   782, 10703, 29873,  8676,     2,    12,    90,   184,   439,\n",
       "             19,  3154,  1140, 11879,     3,  2696,   807,    12,     8,   711,\n",
       "           1403,   993,    13,     4,   363,     7,   807,     5,     4,   402,\n",
       "            556,     3]]),\n",
       " tensor([[    1,   191,    12,  2696,   807,   464, 25972,    30,    39]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = '''Southern California, often abbreviated SoCal, is a geographic and cultural region that generally comprises California's southernmost 10 counties. The region is traditionally described as \"eight counties\", based on demographics and economic ties: Imperial, Los Angeles, Orange, Riverside, San Bernardino, San Diego, Santa Barbara, and Ventura. The more extensive 10-county definition, including Kern and San Luis Obispo counties, is also used based on historical political divisions. Southern California is a major economic center for the state of California and the United States.'''\n",
    "question = \"What is Southern California often abbreviated as?\"\n",
    "\n",
    "# preprocess\n",
    "# build_features(args, train_examples, \"train\", args.train_record_file, word2idx_dict, char2idx_dict)\n",
    "\n",
    "context_idxs, ques_idxs = preprocess(context, question, word2idx_dict)\n",
    "\n",
    "context_idxs = np.insert(context_idxs, 0, 1)\n",
    "ques_idxs = np.insert(ques_idxs, 0, 1)\n",
    "\n",
    "context_idxs = np.expand_dims(context_idxs, axis=0)\n",
    "ques_idxs = np.expand_dims(ques_idxs, axis=0)\n",
    "\n",
    "\n",
    "context_idxs = torch.from_numpy(context_idxs).long()\n",
    "ques_idxs = torch.from_numpy(ques_idxs).long()\n",
    "\n",
    "context_idxs = merge_1d(context_idxs)\n",
    "ques_idxs = merge_1d(ques_idxs)\n",
    "\n",
    "# ones = torch.ones((batch_size, 1), dtype=torch.int64)\n",
    "# self.context_idxs = torch.cat((ones, self.context_idxs), dim=1)\n",
    "# self.question_idxs = torch.cat((ones, self.question_idxs), dim=1)\n",
    "\n",
    "context_idxs, ques_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "\n",
    "# print(context_idxs.shape, ques_idxs.shape)\n",
    "\n",
    "# context_idxs, ques_idxs = data_loader.dataset[0][0], data_loader.dataset[0][2]\n",
    "log_p1, log_p2 = model(context_idxs, ques_idxs)\n",
    "p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "starts, ends = util.discretize(p1, p2, args.max_ans_len, args.use_squad_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6], device='cuda:0'), tensor([6], device='cuda:0'))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts, ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([401])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# shape: 401 and 51\n",
    "data_loader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03.18.21 22:55:21] Evaluating on dev split...\n",
      "[03.18.21 22:55:21] Evaluating on dev split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5951/5951 [00:10<00:00, 581.54it/s, NLL=3.04]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "    log.info(f'Evaluating on {args.split} split...')\n",
    "    nll_meter = util.AverageMeter()\n",
    "    pred_dict = {}  # Predictions for TensorBoard\n",
    "    sub_dict = {}   # Predictions for submission\n",
    "    eval_file = vars(args)[f'{args.split}_eval_file']\n",
    "    with open(eval_file, 'r') as fh:\n",
    "        gold_dict = json_load(fh)\n",
    "    with torch.no_grad(), \\\n",
    "            tqdm(total=len(dataset)) as progress_bar:\n",
    "        for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in data_loader:\n",
    "            # Setup for forward\n",
    "            cw_idxs = cw_idxs.to(device)\n",
    "            qw_idxs = qw_idxs.to(device)\n",
    "            batch_size = cw_idxs.size(0)\n",
    "\n",
    "            # Forward\n",
    "            log_p1, log_p2 = model(cw_idxs, qw_idxs)\n",
    "            y1, y2 = y1.to(device), y2.to(device)\n",
    "            loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "            nll_meter.update(loss.item(), batch_size)\n",
    "\n",
    "            # Get F1 and EM scores\n",
    "            p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "            starts, ends = util.discretize(p1, p2, args.max_ans_len, args.use_squad_v2)\n",
    "\n",
    "            # Log info\n",
    "            progress_bar.update(batch_size)\n",
    "            if args.split != 'test':\n",
    "                # No labels for the test set, so NLL would be invalid\n",
    "                progress_bar.set_postfix(NLL=nll_meter.avg)\n",
    "\n",
    "            idx2pred, uuid2pred = util.convert_tokens(gold_dict,\n",
    "                                                      ids.tolist(),\n",
    "                                                      starts.tolist(),\n",
    "                                                      ends.tolist(),\n",
    "                                                      args.use_squad_v2)\n",
    "            pred_dict.update(idx2pred)\n",
    "            sub_dict.update(uuid2pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 312])\n",
      "tensor([[    1,    24, 49861,  ...,     0,     0,     0],\n",
      "        [    1,    24, 49861,  ...,     0,     0,     0],\n",
      "        [    1,    24, 49861,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  5206,  1696,  ...,     0,     0,     0],\n",
      "        [    1,  5206,  1696,  ...,     0,     0,     0],\n",
      "        [    1,  1383, 77957,  ...,     7,  1383,     3]])\n",
      "torch.Size([64, 312])\n",
      "tensor([[    1,  1383, 77957,  ...,     7,  1383,     3],\n",
      "        [    1,  1383, 77957,  ...,     7,  1383,     3],\n",
      "        [    1,  1383, 77957,  ...,     7,  1383,     3],\n",
      "        ...,\n",
      "        [    1,  1124,   183,  ...,     0,     0,     0],\n",
      "        [    1,  1124,   183,  ...,     0,     0,     0],\n",
      "        [    1,  1124,   183,  ...,     0,     0,     0]])\n",
      "torch.Size([64, 193])\n",
      "tensor([[    1,  1124,   183,  ...,     0,     0,     0],\n",
      "        [    1, 28582,     6,  ...,     0,     0,     0],\n",
      "        [    1, 28582,     6,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,    24,  1323,  ...,     0,     0,     0],\n",
      "        [    1,   216,   426,  ...,     0,     0,     0],\n",
      "        [    1,   216,   426,  ...,     0,     0,     0]])\n",
      "torch.Size([64, 169])\n",
      "tensor([[   1,  216,  426,  ...,    0,    0,    0],\n",
      "        [   1,  216,  426,  ...,    0,    0,    0],\n",
      "        [   1,  216,  426,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  256, 2877,  ...,    0,    0,    0],\n",
      "        [   1,  256, 2877,  ...,    0,    0,    0],\n",
      "        [   1,  256, 2877,  ...,    0,    0,    0]])\n",
      "torch.Size([64, 185])\n",
      "tensor([[    1,   256,  2877,  ...,     0,     0,     0],\n",
      "        [    1,   256,  2877,  ...,     0,     0,     0],\n",
      "        [    1,   256,  2877,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3]])\n",
      "torch.Size([64, 185])\n",
      "tensor([[    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 39501,  ..., 39501,  9533,     3],\n",
      "        ...,\n",
      "        [    1,    24,   171,  ...,     0,     0,     0],\n",
      "        [    1,    24,   171,  ...,     0,     0,     0],\n",
      "        [    1,   149,   546,  ...,     0,     0,     0]])\n",
      "torch.Size([64, 187])\n",
      "tensor([[  1, 149, 546,  ...,   0,   0,   0],\n",
      "        [  1, 149, 546,  ...,   0,   0,   0],\n",
      "        [  1, 149, 546,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1, 149,   4,  ...,   0,   0,   0],\n",
      "        [  1, 149,   4,  ...,   0,   0,   0],\n",
      "        [  1, 149,   4,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "for i, (cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids) in enumerate(data_loader):\n",
    "\n",
    "    print(cw_idxs.shape)\n",
    "    print(cw_idxs)\n",
    "    \n",
    "    if i>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 312])\n",
      "tensor([[    1,    24, 49861,  ...,     0,     0,     0],\n",
      "        [    1,    24, 49861,  ...,     0,     0,     0],\n",
      "        [    1,    24, 49861,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  5206,  1696,  ...,     0,     0,     0],\n",
      "        [    1,  5206,  1696,  ...,     0,     0,     0],\n",
      "        [    1,  1383, 77957,  ...,     7,  1383,     3]])\n",
      "torch.Size([64, 312])\n",
      "tensor([[    1,  1383, 77957,  ...,     7,  1383,     3],\n",
      "        [    1,  1383, 77957,  ...,     7,  1383,     3],\n",
      "        [    1,  1383, 77957,  ...,     7,  1383,     3],\n",
      "        ...,\n",
      "        [    1,  1124,   183,  ...,     0,     0,     0],\n",
      "        [    1,  1124,   183,  ...,     0,     0,     0],\n",
      "        [    1,  1124,   183,  ...,     0,     0,     0]])\n",
      "torch.Size([64, 193])\n",
      "tensor([[    1,  1124,   183,  ...,     0,     0,     0],\n",
      "        [    1, 28582,     6,  ...,     0,     0,     0],\n",
      "        [    1, 28582,     6,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,    24,  1323,  ...,     0,     0,     0],\n",
      "        [    1,   216,   426,  ...,     0,     0,     0],\n",
      "        [    1,   216,   426,  ...,     0,     0,     0]])\n",
      "torch.Size([64, 169])\n",
      "tensor([[   1,  216,  426,  ...,    0,    0,    0],\n",
      "        [   1,  216,  426,  ...,    0,    0,    0],\n",
      "        [   1,  216,  426,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  256, 2877,  ...,    0,    0,    0],\n",
      "        [   1,  256, 2877,  ...,    0,    0,    0],\n",
      "        [   1,  256, 2877,  ...,    0,    0,    0]])\n",
      "torch.Size([64, 185])\n",
      "tensor([[    1,   256,  2877,  ...,     0,     0,     0],\n",
      "        [    1,   256,  2877,  ...,     0,     0,     0],\n",
      "        [    1,   256,  2877,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3]])\n",
      "torch.Size([64, 185])\n",
      "tensor([[    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 36611,  ...,  8799,  2611,     3],\n",
      "        [    1,    80, 39501,  ..., 39501,  9533,     3],\n",
      "        ...,\n",
      "        [    1,    24,   171,  ...,     0,     0,     0],\n",
      "        [    1,    24,   171,  ...,     0,     0,     0],\n",
      "        [    1,   149,   546,  ...,     0,     0,     0]])\n",
      "torch.Size([64, 187])\n",
      "tensor([[  1, 149, 546,  ...,   0,   0,   0],\n",
      "        [  1, 149, 546,  ...,   0,   0,   0],\n",
      "        [  1, 149, 546,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1, 149,   4,  ...,   0,   0,   0],\n",
      "        [  1, 149,   4,  ...,   0,   0,   0],\n",
      "        [  1, 149,   4,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "data_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03.18.21 22:56:11] Dev NLL: 03.04, F1: 58.27, EM: 55.15, AvNA: 64.56\n",
      "[03.18.21 22:56:11] Dev NLL: 03.04, F1: 58.27, EM: 55.15, AvNA: 64.56\n"
     ]
    }
   ],
   "source": [
    "# Log results (except for test set, since it does not come with labels)\n",
    "    if args.split != 'test':\n",
    "        results = util.eval_dicts(gold_dict, pred_dict, args.use_squad_v2)\n",
    "        results_list = [('NLL', nll_meter.avg),\n",
    "                        ('F1', results['F1']),\n",
    "                        ('EM', results['EM'])]\n",
    "        if args.use_squad_v2:\n",
    "            results_list.append(('AvNA', results['AvNA']))\n",
    "        results = OrderedDict(results_list)\n",
    "\n",
    "        # Log to console\n",
    "        results_str = ', '.join(f'{k}: {v:05.2f}' for k, v in results.items())\n",
    "        log.info(f'{args.split.title()} {results_str}')\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        tbx = SummaryWriter(args.save_dir)\n",
    "        util.visualize(tbx,\n",
    "                       pred_dict=pred_dict,\n",
    "                       eval_path=eval_file,\n",
    "                       step=0,\n",
    "                       split=args.split,\n",
    "                       num_visuals=args.num_visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1, 8765,   22,  ...,    0,    0,    0],\n",
       "        [   1, 8765,   22,  ...,    0,    0,    0],\n",
       "        [   1, 8765,   22,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   24, 7029,  ...,    0,    0,    0],\n",
       "        [   1,   24, 7029,  ...,    0,    0,    0],\n",
       "        [   1,   24, 7029,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_dict[:10]\n",
    "# sub_dict\n",
    "cw_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:squad]",
   "language": "python",
   "name": "conda-env-squad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
